<!DOCTYPE html>
<html lang="en" data-dark="false">
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!--
  put your analytics (e.g. Google Analytics) tracking code here
-->

  <!--
  put your search engine verification (e.g. Google Search Console) tag here
-->

  






























<meta name="viewport" content="width=device-width, initial-scale=1">

<title>Il corpus TIGR: un corpus video per lo studio dell'italiano parlato | LABORATORIO SPERIMENTALE</title>

<link rel="icon" href="">

<meta name="title" content="Il corpus TIGR: un corpus video per lo studio dell'italiano parlato">
<meta name="description" content="Dipartimento di Lingue, Letterature e Culture Moderne. ">

<meta property="og:title" content="Il corpus TIGR: un corpus video per lo studio dell'italiano parlato">
<meta property="og:site_title" content="LABORATORIO SPERIMENTALE">
<meta property="og:description" content="Dipartimento di Lingue, Letterature e Culture Moderne. ">
<meta property="og:url" content="https://laboratoriosperimentale.github.io/seminari">
<meta property="og:image" content="">
<meta property="og:locale" content="en_US">

<meta property="twitter:title" content="Il corpus TIGR: un corpus video per lo studio dell'italiano parlato">
<meta property="twitter:description" content="Dipartimento di Lingue, Letterature e Culture Moderne. ">
<meta property="twitter:url" content="https://laboratoriosperimentale.github.io/seminari">
<meta property="twitter:card" content="summary_large_image">
<meta property="twitter:image" content="">


  <meta name="author" content="Silvia">
  <meta property="og:type" content="article">
  <meta property="og:updated_time" content="2025-02-12T13:16:51+00:00">
  <meta property="article:published_time" content="">
  <meta property="article:modified_time" content="2025-02-12T13:16:51+00:00">
  <meta name="revised" content="2025-02-12T13:16:51+00:00">


<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "BlogPosting",
      "author": { "@type": "Person", "name": "Il corpus TIGR: un corpus video per lo studio dell&apos;italiano parlato" },
      "datePublished": "",
      "dateModified": "2025-02-12T13:16:51+00:00",
    
    "name": "Il corpus TIGR: un corpus video per lo studio dell&apos;italiano parlato",
    "description": "Dipartimento di Lingue, Letterature e Culture Moderne. ",
    "headline": "Il corpus TIGR: un corpus video per lo studio dell&apos;italiano parlato",
    "publisher": {
      "@type": "Organization",
      "logo": { "@type": "ImageObject", "url": "" }
    },
    "url": "https://laboratoriosperimentale.github.io/seminari"
  }
</script>

<link rel="alternate" type="application/rss+xml" href="https://laboratoriosperimentale.github.io/seminari/feed.xml">

  <!-- Google Fonts -->
<!-- automatically get url from fonts used in theme file -->

<link rel="preconnect" href="https://fonts.gstatic.com">
<link href="https://fonts.googleapis.com/css2?display=swap&&family=Barlow:ital,wght@0,200;0,400;0,500;0,600;1,200;1,400;1,500;1,600&amp;family=Roboto+Mono:ital,wght@0,200;0,400;0,500;0,600;1,200;1,400;1,500;1,600" rel="stylesheet">

<!-- Font Awesome icons (load asynchronously due to size) -->

<link href="https://use.fontawesome.com/releases/v6.7.0/css/all.css" rel="stylesheet" media="none" onload="this.removeAttribute('media'); this.onload = null;">
<noscript>
  <link href="https://use.fontawesome.com/releases/v6.7.0/css/all.css" rel="stylesheet">
</noscript>

  <!-- third party styles -->
<!-- https://stylishthemes.github.io/Syntax-Themes/pygments/ -->
<link href="https://cdn.jsdelivr.net/gh/StylishThemes/Syntax-Themes/pygments/css-github/pygments-tomorrow-night-eighties.css" rel="stylesheet">

<!-- include all sass in styles folder -->


  
    <link href="/seminari/_styles/-theme.css" rel="stylesheet">
  

  
    <link href="/seminari/_styles/alert.css" rel="stylesheet">
  

  
    <link href="/seminari/_styles/all.css" rel="stylesheet">
  

  
    <link href="/seminari/_styles/anchor.css" rel="stylesheet">
  

  
    <link href="/seminari/_styles/background.css" rel="stylesheet">
  

  
    <link href="/seminari/_styles/body.css" rel="stylesheet">
  

  
    <link href="/seminari/_styles/bold.css" rel="stylesheet">
  

  
    <link href="/seminari/_styles/button.css" rel="stylesheet">
  

  
    <link href="/seminari/_styles/card.css" rel="stylesheet">
  

  
    <link href="/seminari/_styles/checkbox.css" rel="stylesheet">
  

  
    <link href="/seminari/_styles/citation.css" rel="stylesheet">
  

  
    <link href="/seminari/_styles/code.css" rel="stylesheet">
  

  
    <link href="/seminari/_styles/cols.css" rel="stylesheet">
  

  
    <link href="/seminari/_styles/dark-toggle.css" rel="stylesheet">
  

  
    <link href="/seminari/_styles/details.css" rel="stylesheet">
  

  
    <link href="/seminari/_styles/feature.css" rel="stylesheet">
  

  
    <link href="/seminari/_styles/figure.css" rel="stylesheet">
  

  
    <link href="/seminari/_styles/float.css" rel="stylesheet">
  

  
    <link href="/seminari/_styles/font.css" rel="stylesheet">
  

  
    <link href="/seminari/_styles/footer.css" rel="stylesheet">
  

  
    <link href="/seminari/_styles/form.css" rel="stylesheet">
  

  
    <link href="/seminari/_styles/grid.css" rel="stylesheet">
  

  
    <link href="/seminari/_styles/header.css" rel="stylesheet">
  

  
    <link href="/seminari/_styles/heading.css" rel="stylesheet">
  

  
    <link href="/seminari/_styles/highlight.css" rel="stylesheet">
  

  
    <link href="/seminari/_styles/icon.css" rel="stylesheet">
  

  
    <link href="/seminari/_styles/image.css" rel="stylesheet">
  

  
    <link href="/seminari/_styles/link.css" rel="stylesheet">
  

  
    <link href="/seminari/_styles/list.css" rel="stylesheet">
  

  
    <link href="/seminari/_styles/main.css" rel="stylesheet">
  

  
    <link href="/seminari/_styles/paragraph.css" rel="stylesheet">
  

  
    <link href="/seminari/_styles/portrait.css" rel="stylesheet">
  

  
    <link href="/seminari/_styles/post-excerpt.css" rel="stylesheet">
  

  
    <link href="/seminari/_styles/post-info.css" rel="stylesheet">
  

  
    <link href="/seminari/_styles/post-nav.css" rel="stylesheet">
  

  
    <link href="/seminari/_styles/quote.css" rel="stylesheet">
  

  
    <link href="/seminari/_styles/rule.css" rel="stylesheet">
  

  
    <link href="/seminari/_styles/search-box.css" rel="stylesheet">
  

  
    <link href="/seminari/_styles/search-info.css" rel="stylesheet">
  

  
    <link href="/seminari/_styles/section.css" rel="stylesheet">
  

  
    <link href="/seminari/_styles/table.css" rel="stylesheet">
  

  
    <link href="/seminari/_styles/tags.css" rel="stylesheet">
  

  
    <link href="/seminari/_styles/textbox.css" rel="stylesheet">
  

  
    <link href="/seminari/_styles/tooltip.css" rel="stylesheet">
  

  
    <link href="/seminari/_styles/util.css" rel="stylesheet">
  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  


<!-- include all css in styles folder -->



  <!-- third party scripts -->
<script src="https://unpkg.com/@popperjs/core@2" defer></script>
<script src="https://unpkg.com/tippy.js@6" defer></script>
<script src="https://unpkg.com/mark.js@8" defer></script>

<!-- include all js in scripts folder -->


  <script src="/seminari/_scripts/anchors.js"></script>

  <script src="/seminari/_scripts/dark-mode.js"></script>

  <script src="/seminari/_scripts/fetch-tags.js"></script>

  <script src="/seminari/_scripts/search.js"></script>

  <script src="/seminari/_scripts/site-search.js"></script>

  <script src="/seminari/_scripts/table-wrap.js"></script>

  <script src="/seminari/_scripts/tooltip.js"></script>


</head>

  <body>
    







<header class="background" style="--image: url('/seminari/images/orizzontale%20trasp.png')" data-dark="true">
  <a href="/seminari/" class="home">
    
    
      <span class="title-text" data-tooltip="Home">
        
          <span class="title">LABORATORIO SPERIMENTALE</span>
        
        
          <span class="subtitle">Dipartimento di Lingue, Letterature e Culture Moderne</span>
        
      </span>
    
  </a>

  <input class="nav-toggle" type="checkbox" aria-label="show/hide nav">

  <nav>
    
    
      
        <a href="/seminari/seminari/" data-tooltip="Software, datasets, and more">
          Seminari del Laboratorio
        </a>
      
    
      
        <a href="/seminari/autori/" data-tooltip="About our team">
          Autori
        </a>
      
    
      
        <a href="/seminari/contact/" data-tooltip="Email, address, and location">
          Contatti
        </a>
      
    
  </nav>
</header>

    <main>
      <!--
  modify main content of page:
  - add section breaks
  - attach section properties
  - filter out blank sections
-->






  
  
  

  <section class="background" data-size="page">
    <h1 id="il-corpus-tigr-un-corpus-video-per-lo-studio-dellitaliano-parlato">Il corpus TIGR: un corpus video per lo studio dell’italiano parlato</h1>

<h2 id="inserire-tabella-riassuntiva">INSERIRE TABELLA RIASSUNTIVA</h2>

<h2 id="introduzione-al-corpus-tigr">Introduzione al corpus TIGR</h2>
<p>Il corpus d’italiano parlato TIGR è stato raccolto negli anni 2021 e 2022  nei cantoni svizzeri Ticino e Grigioni (da qui il nome) e nasce all’interno di un progetto di ricerca condotto dall’Università della Svizzera Italiana (USI), <strong>InfinIta - La categorizzazione delle fonti di informazione nell’interazione faccia a faccia. Una indagine basata sul corpus di italiano parlato TIGR</strong> (per l’abstract e le pubblicazioni scientifiche: https://data.snf.ch/grants/grant/192771). Il progetto, finanziato dalla Swiss National Science Foundation (SNSF), terminerà il 31 agosto 2025.
Come si legge sul sito dell’USI (E QUI METTEREI IL COLLEGAMENTO IPERTESTUALE AL SITO), il corpus TIGR “documenta interazioni faccia a faccia in situazioni non sperimentali di vario genere: conversazioni a tavola, preparazione di cibo, lezioni e incontri di tutoring, interviste, per 23,5 ore in totale”.</p>

<p>Per condividere il corpus con la comunità scientifica secondo i principi FAIR è nato <a href="https://sharetigr.usi.ch/it/news/feeds/37644"><strong>ShareTIGR</strong></a>, un progetto specificamente dedicato agli <em>open research data</em> (ORD). Al momento, si sta lavorando per rendere il corpus accessibile ad altri ricercatori sul Language Repository of Switzerland LaRS, una sezione del repositorio SWISSUbase.
Dopo aver depositato il corpus sul repositorio, si vorrebbe poi inserire il TIGR su una piattaforma di consultazione e analisi online.
GUARDA L’ABSTRACT PRESO DA SHAREPOINT PER L’INTRODUZIONE</p>

<h2 id="sul-progetto-infinita-perché-è-stato-creato-il-corpus-tigr">Sul progetto InfinIta: perché è stato creato il corpus TIGR?</h2>

<h3 id="le-domande-di-ricerca">Le domande di ricerca</h3>

<p>Il corpus TIGR è nato per cercare di rispondere a sostanzialmente tre domande che riguardano la categorizzazione delle fonti di informazione nell’italiano parlato:</p>

<ol>
  <li>
    <p>A livello semiotico, attraverso quali risorse (indicatori e costruzioni di evidenzialità, strategie discorsive, strategie multimodali, implicature) viene comunicata la fonte dell’informazione?</p>
  </li>
  <li>
    <p>A livello semantico, quali distinzioni relative alla fonte dell’informazione diventano rilevanti? Categorizzazioni specifiche, ad esempio: ‘Il presidente non è in forma. <em>Lo ha detto il suo portavoce durante la conferenza stampa di ieri</em>’ / ‘<em>È evidente dal modo in cui si è comportato durante il dibattito televisivo di ieri</em>’ rispetto a categorizzazioni generiche, ad esempio: ‘<em>Ho sentito dire che</em>/ <em>A quanto pare</em> il presidente non è in forma’</p>
  </li>
  <li>
    <p>A livello pragmatico, come la categorizzazione delle fonti di informazione contribuisce al posizionamento epistemico?</p>
  </li>
</ol>

<h3 id="perché-un--corpus-video-dellitaliano-parlato">Perché un  <ins>corpus video</ins> dell’italiano parlato?</h3>

<p>Sono diversi i motivi che hanno spinto alla creazione di un corpus video:</p>

<ol>
  <li>
    <p>Il video consente lo studio dell’uso integrato di mezzi verbali, mezzi multimodali e risorse situazionali (oggetti a disposizione in una situazione che diventano funzionali alla comunicazione). Nello specifico, la disponibilità di dati videoregistrati permette di:</p>

    <ul>
      <li>
        <p>Individuare le <strong>fonti in situ</strong>, cioè le fonti delle informazioni aquisite durante l’interazione in corso grazie alla percezione diretta e alle inferenze basate su indizi percettivi: <em>‘Hanno suonato alla porta, sarà il postino’</em>, <em>‘Questo ragno si muove… sarà ancora vivo’</em> sono esempi costruiti ad hoc sull’evidenzialità basati su indizi percettivi. Spesso nella letteratura sull’evidenzialità gli esempi sono costruiti a tavolino. Quando però abbiamo dei dati video a disposizione possiamo capire <ins>in modo empirico</ins> quali stimoli eventualmente presenti nella situazione diventano funzionali all’espressione della fonte.</p>
      </li>
      <li>
        <p>Identificare il ruolo della direzione dello sguardo e di certi gesti nel posizionamento epistemico.</p>
      </li>
      <li>
        <p>Comprendere la costruzione del riferimento deittico
   Ad esempio, <em>qui</em>, <em>qua</em>, etc., interpretabili meglio quando sono presenti delle immagini a cui poter fare riferimento.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>La presenza di un riferimento video consente una prospettiva più ricca e dinamica su come la grammatica funzioni e si sviluppi nel contesto di interazioni reali e multi-modali. Infatti, la grammatica (come la sintassi o i segnali discorsivi) da un lato è uno strumento che organizza l’interazione, ma dall’altro può essere influenzata o “emergere” dalle strutture sequenziali delle interazioni, cioè da come si sviluppano e si susseguono gli scambi comunicativi nel tempo. Dato che le interazioni non sono mediate solo dalle parole, ma anche dai gesti, i movimenti o le espressioni facciali, <ins>i video permettono di osservare come si sviluppano le interazioni nel loro contesto sequenziale completo</ins>. Inoltre, consentono di analizzare la <strong>multi-attività</strong>, cioè situazioni in cui il discorso si intreccia con altre attività parallele (ad esempio, una persona che parla mentre cucina o che gesticola durante la conversazione).</p>
  </li>
  <li>
    <p>La variazione diafasica viene meglio studiata grazie al video. È infatti possibile studiare quelle interazioni che generalmente non vengono prese in considerazione se si dispone solamente dell’audio in quanto con la sola documentazione audio si perdono troppe informazioni. Un esempio potrebbe essere l’analisi dell’interazione durante una lezione di guida, inutile se l’interazione è documentata solo tramite registrazione audio.</p>
  </li>
</ol>

<h3 id="composizione-del-corpus">Composizione del corpus</h3>

<p>Per conoscere la struttura del TIGR nel contesto del progetto InfinIta e lo statuto del corpus tra i vari corpora linguistici esistenti, si rimanda all’articolo <a href="https://sharetigr.usi.ch/it/news/feeds/37812"><em>Composizione del corpus</em></a>.</p>

<p>Design iniziale del corpus TIGR (2020)
<img src="/images/seminar-images/tigr/image-10.png" alt="plain image"></p>

<p>Secondo il disegno iniziale, l’idea era di includere diversi tipi di interazione: intervista, conversazione a tavola, preparazione di un pasto, lavori di gruppo e lezioni; per un totale di 28 ore e 39 eventi.</p>

<p>Però strada facendo ci sono stati dei riadattamenti del design del corpus a causa dell’avvento della Pandemia di COVID-19. Per saperne di più sulle problematiche nella raccolta dei dati legate alla Pandemia , leggere l’articolo <a href="https://sharetigr.usi.ch/it/news/feeds/38556"><em>Raccogliere dati linguistici ai tempi del COVID-19</em></a>.
Alla fine del processo sono state ottenute 23h 30’ di videoregistrazione, per un totale di 23 eventi e 115 parlanti.</p>

<p>La versione finale del corpus TIGR
<img src="/images/seminar-images/tigr/image-11.png" alt="plain image"></p>

<p>Per quanto riguarda i contesti didattici, sono state registrate lezioni di tre tipi:</p>
<ul>
  <li>sessioni di tutoring in architettura,</li>
  <li>lezioni di teatro, di musica e di restauro e</li>
  <li>lezioni di glottodidattica e di cultura generale nella scuola superiore in cui gli studenti si cimentavano in lavori di gruppo e presentazioni.</li>
</ul>

<p>Ai parametri del design iniziale sono stati aggiunti l’<strong>istituzionalità</strong> e il <strong>ruolo dei partecipanti</strong>. Esistono tipi di interazione istituzionali, come l’intervista o una lezione, e tipi di interazione non istituzionali, come la preparazione di un pasto o la conversazione a tavola. Il parametro dell’istituzionalità influisce sul ruolo dei partecipanti, che può essere simmetrico, asimmetrico o variabile. Prendendo in considerazione quest’ultimo parametro, è possibile studiare la dimensione epistemica in relazione al ruolo dei partecipanti, e quindi capire, ad esempio, se un rapporto di asimmetria gerarchica determina anche un’asimmetria epistemica.
Il movimento dei partecipanti e la manipolazione degli oggetti hanno a che fare con la multi-attività, la quale ha un effetto sull’organizzazione sequenziale del discorso.</p>

<p>PER GLI ESEMPI MI PIACEREBBE CREARE DEI COLLEGAMENTI IPERTESTUALI AL VIDEO DEL SEMINARIO.</p>

<h2 id="parlanti-del-tigr">Parlanti del TIGR</h2>

<h3 id="reclutamento-dei-parlanti">Reclutamento dei parlanti</h3>

<p>Il contatto e il reclutamento dei partecipanti sono descritti in dettaglio nel seguente articolo: <a href="https://sharetigr.usi.ch/it/news/feeds/38402"><em>Il lavoro sul campo: ricerca e contatto dei partecipanti</em></a>. Nel testo dell’articolo è presente anche il link al questionario che è stato sottoposto ai parlanti.</p>

<p>Il requisito fondamentale che i parlanti dovevano possedere per essere scelti come partecipanti era di essere <strong>italofoni</strong>. Non era necessario che la lingua italiana fosse la lingua madre (L1).</p>

<p>Per un approfondimento sul questionario che i parlanti hanno dovuto compilare: <a href="https://sharetigr.usi.ch/en/news/feeds/37690"><em>Digitisation of the TIGR participant questionnaires</em></a></p>

<h3 id="dichiarazioni-di-consenso-informato-esigenze-della-ricerca-esigenze-legali-e-questioni-etiche">Dichiarazioni di consenso informato: esigenze della ricerca, esigenze legali e questioni etiche</h3>

<p>Per redigere la dichiarazione di consenso informato è stato utilizzato un modello interno all’USI e sono stati consultati la Commissione etica e il Servizio legale dell’università.
Inoltre, si è fatto riferimento a normative, come la Legge federale sulla protezione dei dati, e linee guida, come quelle indicate da FORS.
Per una riflessione approfondita sulle tematiche legali, si rimanda all’articolo <a href="https://www.chord-talk-in-interaction.usi.ch/news/feeds/36387"><em>Social interaction is among people. Legal, technical, and ethical explorations about personal information and its removal in talk-in-interaction as data</em></a>.</p>

<p>Prevedere fin dall’inizio la pubblicazione dei dati (video) richiede una riflessione su due tematiche principali:</p>

<ol>
  <li>Come gestire la de-identificazione dei parlanti?</li>
  <li>Come descrivere in modo informativo ma non limitante il futuro riuso dei dati?</li>
</ol>

<p>Qui di seguito, la struttura del documento di dichiarazione di consenso informato che è stato fatto firmare ai partecipanti.</p>

<p>Parte A. Documento informativo</p>
<ol>
  <li>Introduzione</li>
  <li>Descrizione del progetto di ricerca per un pubblico non specialista</li>
  <li>Descrizione dell’evento e modalità di video-registrazione</li>
  <li>Confidenzialità e protezione dei dati</li>
  <li>Conservazione e utilizzo dei dati</li>
  <li>Diritti dei partecipanti allo studio</li>
  <li>Contatti</li>
</ol>

<p>Parte B. Consenso informato
Ai parlanti è stato fatto scegliere tra due misure di de-identificazione:</p>
<ul>
  <li>default&gt; pseudonimi nella trascrizione, silenzi nella traccia audio, misure di de-identificazione nei metadati</li>
  <li>misure supplementari&gt; alterazione della voce nella traccia audio (6 richieste), applicazione di filtri nella traccia video (15 richieste)</li>
</ul>

<p>Per saperne di più a proposito della stesura del documento di dichiarazione di consenso informato da parte del team di InfinIta, si legga l’articolo <a href="https://sharetigr.usi.ch/it/news/feeds/38259"><em>Dichiarazioni di consenso informato</em></a>.</p>

<h4 id="misure-di-de-identificazione-dei-dati">Misure di de-identificazione dei dati</h4>

<p>Per quanto riguarda le misure di de-identificazione dei dati inseriti dai partecipanti, sono stati adottati alcuni provvedimenti:</p>
<ul>
  <li>Ad ogni partecipante è stato attrbuito un codice informatore nel formato inf-N.</li>
  <li>L’età è stata ridotta a un intervallo.</li>
  <li>Per quanto riguarda le informazioni sul luogo di provenienza, è stato inserito lo Stato (ad esempio, Svizzera) e il cantone (o la regione nel caso dell’Italia).</li>
</ul>

<h3 id="dati-sociolinguistici-ricavati">Dati sociolinguistici ricavati</h3>

<p>Di seguito si riportano alcuni grafici sui principali dati sociolinguistici che riguardano il campione di parlanti considerato.</p>

<ul>
  <li>
    <h4 id="genere-e-età">Genere e età</h4>
    <p><img src="/images/seminar-images/tigr/image-15.png" alt="plain image"></p>

    <p><em>Come si può vedere dal grafico a sinistra,  il corpus è abbastanza bilanciato con una presenza femminile (53%) di poco superiore a quella maschile (47%).</em>
<em>Nel grafico a destra vengono mostrate le fascie d’età, con una sovrarappresentazione della fascia degli studenti universitari (20-29).</em></p>
  </li>
  <li>
    <h4 id="origine-dei-parlanti">Origine dei parlanti</h4>
    <p><img src="/images/seminar-images/tigr/image-16.png" alt="plain image"></p>

    <p><em>La maggior parte dei partecipanti ha frequentato la scuola elementare in Italia e in Svizzera.</em></p>

    <p><img src="/images/seminar-images/tigr/image-17.png" alt="plain image">
<em>Qui vengono mostrati i dati specifici sulle regioni italiane e sui cantoni svizzeri in cui i parlanti hanno frequentato la scuola elementare. Nonostante un certo bias geografico per quanto riguarda l’Italia, con Lombardia e Piemonte in testa, diverse regioni sono rappresentate, sia del centro sia del sud.</em>
<em>In merito alla Svizzera, la maggior parte dei parlanti ha frequentato la scuola elementare nei cantoni Ticino e Grigioni.</em></p>
  </li>
  <li>
    <h4 id="luogo-di-lavoro-o-studio-in-svizzera">Luogo di lavoro o studio in Svizzera</h4>
    <p><img src="/images/seminar-images/tigr/image-18.png" alt="plain image">
<em>La maggior parte dei parlanti svolge la sua attività principale (studio o lavoro) in Ticino (64%). Al secondo posto troviamo i Grigioni (34%).</em></p>
  </li>
  <li>
    <h4 id="repertorio-linguistico">Repertorio linguistico</h4>
    <p><img src="/images/seminar-images/tigr/image-19.png" alt="plain image">
<em>La maggior parte dei parlanti ha dichiarato di essere plurilingue (due, tre o addirittura più di quattro lingue nel repertorio). La lista delle lingue conosciute dai partecipanti sono riportate nel grafico di destra.</em></p>
  </li>
  <li>
    <h4 id="istruzione-e-professione">Istruzione e professione</h4>
    <p><img src="/images/seminar-images/tigr/image-20.png" alt="plain image">
<em>Il livello di istruzione principale è la scuola secondaria di secondo grado. Trattandosi per la maggio parte di studenti universitari, era l’ultimo grado di istruzione completato.</em></p>
  </li>
</ul>

<h2 id="luoghi-dove-sono-stati-registrati-gli-eventi-del-tigr">Luoghi dove sono stati registrati gli eventi del TIGR</h2>
<p>Come è stato detto, la registrazione delle interazioni è avvenuta nei cantoni Ticino e Grigioni. Le località all’interno dei due cantoni sono determinate in modo opportunistico in base alla disponibilità dei parlanti. In una seconda fase della raccolta, la presa di contatto ad hoc con le istituzioni scolastiche ha permesso di ampliare la copertura geografica del corpus.</p>

<p>In Ticino sono stati registrati 9 eventi in 7 piccoli centri e altri 9 eventi in 2 grandi centri, per un totale di 18 eventi in 9 località.
Nei Grigioni sono stati registrati 4 eventi in 1 piccolo centro e altri 4 eventi in 1 grande centro, per un totale di 5 eventi in 2 località.</p>

<p>Si precisa che il corpus non è disegnato per documentare la variazione diatopica dell’italiano parlato in Svizzera.</p>

<h4 id="misure-di-de-identificazione-del-luogo-di-registrazione">Misure di de-identificazione del luogo di registrazione:</h4>
<ul>
  <li>il luogo di registrazione viene descritto solamente dal Cantone e dalle dimensioni del centro abitato (&gt; o &lt;10,000 abitanti).</li>
</ul>

<h2 id="impostazione-tecnica-delle-registrazioni-post-produzione-e-trascrizione">Impostazione tecnica delle registrazioni, post-produzione e trascrizione</h2>

<h3 id="strumentazione-utilizzata-e-post-produzione">Strumentazione utilizzata e post-produzione</h3>
<p>L’impostazione di base è stata quella di andare sul luogo della registrazione, installare i dispositivi e lasciare che i parlanti interagissero da soli. Solamente nelle interazioni didattiche e nelle interviste erano presenti anche i ricercatori.
Una volta conclusesi le interazioni, i ricercatori venivano contattati dai partecipanti tramite Whatsapp.</p>

<p>Per informarsi sulla strumentazione utilizzata per le registrazioni e sulla post-produzione si veda <strong>collegamento ipertestuale con il sito del corpus “Registrazioni audio e video”</strong> e l’articolo <a href="https://sharetigr.usi.ch/it/news/feeds/37851"><em>Dall’evento al dataset</em></a>.</p>

<h3 id="la-trascrizione">La trascrizione</h3>

<p>Per la trascrizione è stato utilizzato il software ELAN, v. 6.7.
È stato inoltre adottato il sistema GAT2 (Gesprächsanalytische Transkriptionssystem):</p>
<ul>
  <li>funzionale a una trascrizione tramite software e machine-readable</li>
  <li>integrato in editor digitali (per esempio EXMARaLDA)</li>
  <li>dotato di tre livelli di granularità: minimal script, basic script e fine script (quello più dettagliato e usato per il corpus TIGR)</li>
</ul>

<p>Alla guida interna sono stati aggiunti:</p>
<ul>
  <li>una lista di lemmi per uniformare la grafia delle interiezioni</li>
  <li>la trascrizione del raddoppiamento fonosintattico (ex., <em>va bbene</em>, <em>e nniente</em> )</li>
  <li>l’uso del simbolo ~ per le interruzioni udibili di una parola (in particolare, glottal stop), per esempio in esitazioni o ripartenze</li>
</ul>

<p>Di seguito sono riportate alcune delle convenzioni GAT2 utilizzate nella trascrizione delle registrazioni</p>

<p><img src="/images/seminar-images/tigr/image-21.png" alt="plain image"></p>

<p><img src="/images/seminar-images/tigr/image-22.png" alt="plain image"></p>

<p>Da notare l’annotazione del comportamento non verbale (guarda nell’immagine sopra in  “Laughter and crying”) che funziona con la logica del tag.</p>

<p><img src="/images/seminar-images/tigr/image-23.png" alt="plain image"></p>

<p>Inoltre, sono state adottate convenzioni di trascrizione multimodale di Modada per il tier “ambient noises”, come nel seguente esempio:</p>

<p><img src="/images/seminar-images/tigr/image-24.png" alt="plain image"></p>

<h4 id="misure-di-de-identificazione-di-persone-e-luoghi-nella-trascrizione">Misure di de-identificazione di persone e luoghi nella trascrizione</h4>

<p>Sono stati attribuiti <strong>pseudonimi</strong> solo ai partecipanti all’interazione in corso, come si vede nell’esempio di seguito:</p>

<p><img src="/images/seminar-images/tigr/image-25.png" alt="plain image"></p>

<p>Per i nomi delle altre persone è stato adottato il formato PERSONNAME, numerato progressivamente:</p>

<p><img src="/images/seminar-images/tigr/image-26.png" alt="plain image"></p>

<p>Stessa cosa è stata fatta per i nomi di luoghi, adottando il formato PLACENAME:</p>

<p><img src="/images/seminar-images/tigr/image-27.png" alt="plain image"></p>

<p>Idem per le istituzioni, per le quali si è adottato il formato INSTITUTIONNAME</p>

<h4 id="la-segmentazione-in-elan">La segmentazione in Elan</h4>

<p>La segmentazione non rappresenta necessariamente un’unità significativa sul piano linguistico.
La segmentazione è stata pensata per essere funzionale ad una trascrizione accurata, come nel caso di sovrapposizioni multiple.
Vedi esempio video al minuto 1:07:06 fino a 1:09:56.</p>

<p>Il problema di come trascrivere le sovrapposizioni si pone in particolare nel caso degli schismi. Non si tratta solamente di conversazioni parallele, ma a volte c’è anche uno spostamento associato. Facciamo l’esempio delle conversazioni a tavola: quando due persone si alzano e vanno in cucina e altre due rimangono a tavola si hanno due conversazioni parallele. La stessa cosa accade durante le lezioni di restauro quando due gruppi lavorano in due parti diverse della chiesa.</p>

<p>Esempio a 1:10:42 fino a 01:11:48 -&gt; crea collegamento ipertestuale</p>

<h4 id="la-derivazione-di-trascrizioni-in-formato-testo-in-stile-dialogo-teatrale">La derivazione di trascrizioni in formato testo in stile “dialogo teatrale”</h4>

<p>Come esportare la trascrizione da ELAN e creare un formato leggibile?
Come abbiamo visto, la prima trascrizione avviene su ELAN. Da questa trascrizione possono derivate altri due tipi di trascrizione:</p>
<ul>
  <li>
    <p>una trascrizione in stile “dialogo teatrale” e formato TXT, come questa:
<img src="/images/seminar-images/tigr/image-28.png" alt="plain image"></p>

    <p>Questo tipo di trascrizione offre un’approssimazione grafica dell’organizzazione della conversazione in turni e una buona base per un’analisi sequenziale.
Inoltre, costituisce un input per l’annotazione delle fonti di informazione all’interno del progetto InfinIta, eseguita nel programma INCEpTION.
Infine, il formato TXT è semplice e interoperabile.</p>

    <p>Come fare per passare da una trascrizione ELAN a una trascrizione di questo tipo?
Si può esportare da ELAN la trascrizione in formato testo “tradizionale”, con o senza timecode e con la formattazione automatica dei turni.
Però sono stati riscontrati alcuni problemi, tra cui:</p>
    <ul>
      <li>se si intende esportare la trascrizione con il timecode, il file risulta illeggibile</li>
      <li>la messa in sequenza automatica dei turni non è sempre intuitiva</li>
    </ul>

    <p>La soluzione è stata quella di condurre una <strong>procedura semi-automatica (script Python)</strong></p>
    <ul>
      <li>la trascrizione veniva esportata da ELAN come trascrizione in formato “tradizionale” e con l’allineamento verticale delle parentesi quadre</li>
      <li>Attraverso degli script sono stati eliminati i timecode tranne quelli che segnano i tempi iniziali dei segmenti (creati su ELAN), che compaiono all’incirca ogni 10 secondi. Sono, poi, state collocate delle ancore “((TC))” nel testo, come si vede in questo esempio
<img src="/images/seminar-images/tigr/image-29.png" alt="plain image">
</li>
      <li>Sono stati eliminati i nomi di parlanti superflui e sono stati concatenati i segmenti</li>
      <li>Si è formattato manualmente le trascrizioni quando presentavano sovrapposizioni di più di due parlanti</li>
    </ul>
  </li>
  <li>
    <p>Una trascrizione in versione tokenizzata, di cui si parlerà nel paragrafo successivo.</p>
  </li>
</ul>

<h4 id="verso-una-versione-tokenizzata-delle-trascrizioni">Verso una versione tokenizzata delle trascrizioni</h4>

<p>I due tipi di trascrizione, quella originale in ELAN e quella in stile “dialogo teatrale” in formato TXT, non sono tokenizzate.
Cos’è la tokenizzazione? È la divisione di un testo in “token”, cioè unità linguisticamente pertinenti di varia complessità. È indispensabile per l’inserimento in un database e ai fini della ricerca lessicometrica, morfo-sintattica, fonologica, ecc. Fornisce, infine, gli input per le procedure di annotazione automatica (per esempio, l’annotazione delle parti del discorso e la lemmatizzazione)</p>

<p>Per questa procedura di tokenizzazione delle trascrizioni si sta collaborando con l’azienda <em>Linguisticbits</em> del Dr. Thomas Schmidt.
La procedura comprende i seguenti step, elencati in ordine di precedenza:</p>
<ol>
  <li>Ricongiungimento dei frammenti di parola creati ai confini dei segmenti in ELAN, che avverrà in maniera in parte automatica, grazie all’uso di un lessico estratto da ItTenTen, e in parte manuale</li>
  <li>Concatenazione dei segmenti ELAN in “contributi” (si tratta di un’approssimazione dell’unità “turno”)</li>
  <li>Divisione automatica dei contributi in parole</li>
  <li>Conversione in un documento XML conforme all’ISO/TC 37/SC 4, 2016 (standard ISO per la trascrizione della lingua parlata, codice CLARIN: https://standards.clarin.eu/sis/views/view-format.xq?id=fTEISpoken).
  A proposito degli standard ISO per la trascrizione della lingua parlata si cita l’articolo H. Hedeland &amp; T. Schmidt. The TEI-based ISO Standard ‘Transcription of spoken language’as an Exchange Format within CLARIN and beyond. _Selected papers from the CLARIN Annual Conference 2021._Ed. M. Monachini &amp; M. Eskevich. Linköping Electronic Conference Proceedings 189, pp. 34-35. DOI: https://doi.org/10.3384/9789179294441</li>
</ol>

<h2 id="condivisione-dei-dati">Condivisione dei dati</h2>

<p>La condivisione e il riuso dei dati è un ciclo: dei ricercatori producono dati per altri ricercatori che li riusano.
I due momenti di condivisione e riuso sono rappresentati graficamente nelle immagini qui sotto:</p>

<p><img src="/images/seminar-images/tigr/image-31.png" alt="plain image">
<img src="/images/seminar-images/tigr/image-32.png" alt="plain image"></p>

<p>Dal punto di vista tecnico le infrastrutture digitali (sono quelle che si vedono nel mezzo) sono cruciali in questo processo.
Nella condivisione e nel riuso dei dati sono contemplati tre mezzi:</p>
<ol>
  <li>repositorio</li>
  <li>piattaforma per la consultazione online</li>
  <li>l’invio dei dati a qualcuno tramite e-mail,</li>
</ol>

<p>Un quarto mezzo potrebbe essere rappresentato dalle “data sessions”, ovvero incontri faccia a faccia dove si lavora sui dati.</p>

<p>L’invio di dati tramite e-mail non assicura che i dati siano reperibili e accessibili a chi non li conosca già. Quindi si considera questa modalità non aderente ai principi FAIR, come invece sono le prime due, cioè il repositorio e la piattaforma digitale. Infatti, il catalogo e la regolazione degli accessi assicurano la reperibilità e l’accesso ai dati.</p>

<p><img src="/images/seminar-images/tigr/image-33.png" alt="plain image"></p>

<h3 id="il-repositorio">Il repositorio</h3>

<p>Nel caso del corpus TIGR verrà usato il <strong>repositorio LaRS</strong>, la sezione linguistica del repositorio <a href="https://www.swissubase.ch/en/">SWISSUbase</a>. Un articolo di approfondimento in inglese per chi fosse interessato: <a href="https://sharetigr.usi.ch/it/news/feeds/37958"><em>Exploring LaRS @ SWISSUbase</em></a>.
Il repositorio LaRS è organizzato secondo tre livelli gerarchici:</p>
<ol>
  <li>Studi</li>
  <li>Dataset (entità scaricabile)</li>
  <li>Documenti</li>
</ol>

<p>Ad ogni livello ci sono dei metadati, alcuni obbligatori e altri facoltativi, che l’utente del repositorio deve inserire.</p>

<p><img src="//images/seminar-images/tigr/image-34.png" alt="plain image"></p>

<p>Nell’immagine sopra i dataset che verrano caricati.
Ci sarà un dataset generale di documentazione che contiene la documentazione del corpus intero (documentazione metodologica, consensi informati, ecc.).
Ci saranno poi i dataset dei singoli eventi. Di ogni evento ci sarà una versione leggera e una versione completa (che contiene le singole tracce audio). All’interno di ciascun dataset saranno raccolti dati video, dati audio, le trascrizioni e file di metadati.
L’ultimo dataset sarà un dataset di sole trascrizioni, pensando a coloro che hanno la necessità di fare ricerca sulle trascrizioni e non hanno bisogno di visionare o di ascoltare i file multimediali.</p>

<p>Il repositorio assegna un DOI a ciascun dataset.
Il dataset è l’unità scaricabile.</p>

<h4 id="metadati">Metadati</h4>

<p>Il repositorio mette a disposizione dei campi predefiniti, alcuni obbligatori alcuni facoltativi. Si è pensato di aggiungere anche delle tabelle (in formato CSV) con i metadati per ogni singolo evento.</p>

<p><img src="/images/seminar-images/tigr/image-35.png" alt="plain image"></p>

<p>Come si vede nell’immagine per ogni singolo evento il cuore è la tabella più centrale con le caratteristiche di base dell’evento (come il numero di partecipanti, il genere di interazione, e così via). La tabella centrale rinvia poi a una serie di altre tabelle. A sinistra si vedono due tabelle con i parlanti e i luoghi del TIGR. I parlanti del TIGR sono collegati al singolo evento tramite l’elenco dei partecipanti all’evento.
L’evento è poi associabile all’elenco dei file video, all’elenco dei file audio e all’elenco delle trascrizioni.</p>

<h3 id="verso-la-messa-a-disposizione-in-una-piattaforma-digitale-per-la-consultazione-online">Verso la messa a disposizione in una piattaforma digitale per la consultazione online</h3>

<p>Ovviamente il repositorio è uno scenario di riuso che suppone il download dei dati sul proprio computer. Questo ha i suoi vantaggi, come la grande libertà di quello che si può fare con questi dati, e i suoi svantaggi, come quello di dover avere sul proprio computer gli strumenti per leggere i dati scaricati.
La piattaforma online, al contrario, è percepita da molti come più comoda perché non richiede il download di alcun strumento di analisi.</p>

<p>Nel contesto del <a href="https://www.liri.uzh.ch/en/projects/FAIR-FI-LD.html">progetto FAIR-FI-LD</a> condotto dall’Università di Zurigo a cui partecipa tra gli altri anche l’USI (in particolare l’Istituto di Studi Italiani, o ISI), si vuole depositare il TIGR nel <a href="https://www.liri.uzh.ch/en/services/LiRI-Corpus-Platform-LCP.html">LiRI Corpus Platform (o LCP)</a>. Questa piattaforma online è stata creata dal LiRI (Linguistic Research Infrastructure), un dipartimento dell’Università di Zurigo. Per saperne di più sul LiRI e di che cosa si occupa, qui è riportata la home page del sito: https://www.liri.uzh.ch/en.html.
Grazie alla collaborazione con <em>Linguisticbits</em>, di cui si è parlato sopra, si sta cercando di definire una procedura di upload in LCP di trascrizioni XML tokenizzate.</p>

<p><a href="https://sharetigr.usi.ch/it/news/feeds/38003">Grouping the TIGR data for reuse</a></p>

<p>Post sul blog scientifico sulla trascrizione in ELAN:</p>

<ul>
  <li>Contributo blog del 2 maggio 2024: <a href="https://sharetigr.usi.ch/it/news/feeds/38046">Morfologia delle trascrizioni, parte I: leggibili in che modo?</a>
</li>
  <li>Contributo blog del 9 maggio 2004: <a href="https://sharetigr.usi.ch/it/news/feeds/38066">Morfologia delle trascrizioni, parte II: codificare il tempo</a>
Video associato: https://www.youtube.com/watch?v=Ileqblg23_o</li>
  <li>Contributo blog del 6 giugno 2004: <a href="https://sharetigr.usi.ch/it/news/feeds/38075">Morfologia delle trascrizioni, parte IV: allineamento temporale e segmentazione</a>
Video associato: https://youtu.be/rUkGMdGEZbM</li>
  <li>Contributo vlog del 13 giugno 2004: <a href="https://sharetigr.usi.ch/it/news/feeds/38294">Morfologia delle trascrizioni, parte V: gestire le sovrapposizioni</a>
Video associato: https://youtu.be/1sTw4s-9f44</li>
</ul>

<p>Riferimenti:</p>

<ul>
  <li>Brugman, H., Russel, A. (2004). Annotating Multimedia/ Multi-modal resources with ELAN. In: Proceedings of LREC 2004, Fourth International Conference on Language Resources and Evaluation.</li>
  <li>Selting, M., Auer, P., Barth-Weingarten, D., Bergmann, J., Bergmann, P., Birkner, K., Couper-Kuhlen, E., Deppermann, A., Gilles, P., Günthner, S., Hartung, M., Kern, F., Mertzlufft, C., Meyer, C., Morek, M., Oberzaucher, F., Peters, J., Quasthoff, U., Schütte, W., &amp; Uhmann, S. (2011). A system for transcribing talk-in-interaction: GAT 2 translated and adapted for English by Elizabeth Couper-Kuhlen and Dagmar Barth-Weingarten. Gesprächsforschung, 12, 1-51. http://www.gespraechsforschung-online.de/heft2011/heft2011.html</li>
</ul>

<p>A proposito, invece, delle tecniche di de-identificazione si riporta il link al sito del corpus <strong>De-identificazione</strong>.</p>

<p><a href="https://sharetigr.usi.ch/it/st/publications">Pubblicazioni e presentazioni nelle quali sono stati usati i dati TIGR</a></p>

<p>(dall’abstract che ho trovato su sharepoint, che dovrebbe integrare l’introduzione)
The TIGR corpus of spoken Italian includes 23.5 hours of video-recorded and transcribed discourse and was gathered by a team of linguists at USI Università della Svizzera italiana in the Swiss cantons Ticino and Grisons in 2021-2022.
-We describe the corpus design and some changes it underwent during fieldwork; the interaction with the speakers, including their informed consent to participate in the study; the set-up of audio and video recordings; sociolinguistic characteristics of the participants; transcription conventions and techniques; workflows of transcript processing in view of qualitative analysis and annotation; de-identification measures; scenarios of data reuse; the organization of the data and metadata on LaRS; an open science approach to problem solving during the preparation of the data to be shared; future perspectives.- ABSTRACT DEL VIDEO??
TIGR was collected within a research project conducted at USI and focused on epistemic aspects of talk (InfinIta, SNSF grant no. 192771). At the same time, it was designed to increase the diversity of available resources for spoken Italian (for an overview see Mauri et al. 2019). It includes 23.5h of video recordings documenting 23 face-to-face interactions. These vary as to genre and as to external criteria (Sinclair &amp; Ball 1996), more specifically event-related parameters (Deppermann/Hartung 2011:423-424) such as institutionality, the number of participants, speaker roles and the presence of multi-activity (Mondada 2009): table conversations (6h5’), food preparation (1h40’), tutoring encounters (4h40’), lessons and practical instruction (7h20’), interviews (3h40’). The data collection process underwent some changes due to the Covid-19 pandemic, which had an impact on the corpus structure. The 115 speakers are 10-70 years old (most represented range: 20-29 years) and about 3/4 of them finished a higher secondary school. They declared their consent to data use and re-use for scientific purposes and expressed some de-identification demands. The technical set-up included two camcorders and 2-4 pocket audio recorders equipped with clip-on microphones, all synchronized through timecode generators. The A/V files were aligned and cut to equal length in Adobe Premiere. The team then transcribed them in ELAN (Sloetjes/Seibert 2016) using an adapted version of the GAT 2 conventions (Selting et al. 2011). A transcription technique was adopted that privileged the alignment of segment boundaries with boundaries of overlapping speech, such as to facilitate the revision of transcripts in ELAN and the manual layout of complex sequences with overlapping speech. Proper names were pseudonymized.
The data will be made available on the SWISSUbase repository using the metadata scheme provided by LaRS, which is tailored for data in linguistics. The data will be downloadable upon signing a user agreement with the corpus owners. To enhance interoperability and reusability, we plan to provide two transcript versions in addition to the EAF file generated by ELAN. By now, we have implemented a script-assisted workflow to produce TXT transcripts that are optimized for the human eye and preserve a reduced amount of timecode stamps. Later we intend to create tokenized transcripts readable by corpus linguistic software. In A/V files we are masking faces and voices, where so required, and replacing proper names by noise. For each recorded event, we are editing a single compact, easy-to-use movie file with split screen and mixed audio. Once ready, the corpus will be uploaded to the repository, completed by metadata and documentation. Users could have the following download options: event by event, either a full version (A/V files, compact movie, EAF file, transcripts) or a light version (compact movie, transcripts); transcripts only for all events at once, raw TXT or tokenized.
While preparing the data, we are step by step building a webpage to present the corpus. In parallel, we use a lab blog (sharetigr.usi.ch) to publicly report on our experience and discuss issues we are facing, thus building a case study of open research data practices in linguistics.
A desirable further step is to make the corpus accessible on a platform that allows for on-line viewing and query. Currently, no such platform is available in Switzerland. USI has started a collaboration with LiRI (Linguistic Research Infrastructure, University of Zurich) to explore possible software developments.</p>

<p>(Da Linkedin)
Lo scorso mese è iniziato il progetto ShareTIGR , il cui obiettivo è di condividere con la comunità scientifica il corpus TIGR, un insieme di materiali per lo studio dell’italiano parlato raccolto nei cantoni svizzeri Ticino e Grigioni. Il presente contributo presenta in breve il progetto e inaugura una serie di blog post che racconteranno le attività del team in carico.</p>

<p>Il corpus TIGR documenta interazioni che si sono svolte faccia a faccia negli anni 2021-2022 - in periodo pandemico, dunque! - in situazioni di vario genere: conversazioni a tavola, preparazione di cibo, incontri di tutoring in architettura, lezioni, interviste. Le interazioni sono state registrate con due telecamere e microfoni da bavero e in seguito trascritte mediante un’applicazione (ELAN ) che associa ogni pezzo di testo al/la parlante che l’ha prodotto e all’intervallo corrispondente del file video. I materiali sono stati raccolti nel quadro di una ricerca finanziata dal Fondo Nazionale Svizzero (il progetto InfinIta sulle fonti d’informazione nell’italiano parlato, 2020-2024), ma sono ricchi di informazioni utili a indagare una vasta gamma di temi oltre quelli previsti dal progetto d’origine. I corpora orali possono infatti essere usati per studiare in diverse prospettive l’interazione, il discorso, il lessico, la grammatica, la variazione geografica e sociale della lingua.</p>

<p>Condizione del riuso dei dati è che essi siano reperibili, accessibili tecnicamente e disponibili in formati di ampia diffusione e interoperabili, in breve che siano FAIR (findable, accessible, interoperable, reusable, Wilkinson et al. 2016). I dati del TIGR sono stati raccolti in tal modo da poter soddisfare questi criteri e contemporaneamente assicurare un’adeguata protezione dei dati personali (sul difficile bilanciamento delle varie esigenze si vedano Diaz 2022 e Miecznikowski e Profazi 2023b). Nello specifico, ogni partecipante registrata/o ha espresso il proprio consenso all’uso dei dati dopo essere messa/o a conoscenza degli scopi dell’indagine e delle modalità di diffusione dei dati. In ShareTIGR, elaboreremo ulteriormente i dati, eliminando certe informazioni personali, preparando file audio-video maneggevoli, convertendo e formattando le trascrizioni, redigendo descrizioni a vari livelli e preparando metadati leggibili dai motori di ricerca. Infine, li depositeremo su SWISSUbase , un repositorio scientifico svizzero per le scienze sociali e la linguistica. Gli utenti interessati potranno così scaricare i documenti e usarli ai fini delle proprie ricerche, dopo essersi registrati e aver firmato un accordo che precisa le modalità e gli scopi del riuso.</p>

<p>Dopo il deposito su repositorio, un ulteriore scenario di condivisione può essere quello di inserire i documenti su una piattaforma che permetta la loro consultazione e analisi online. Piattaforme esistenti per i corpora orali come il sito del corpus KiParla (Mauri e Goria 2018, Miecznikowski e Profazi 2023a), la Datenbank für Gesprochenes Deutsch DGD (Schmidt 2014) o il Corpus de LAngue Parlée en Interaction CLAPI  mostrano i vantaggi e il potenziale della consultazione online. Ciò è emerso chiaramente da una serie di giornate di studio organizzate nel quadro di un progetto attualmente in corso all’USI, in collaborazione con altre università svizzere, co-finanziato da swissuniversities e volto a esplorare “Data-sharing skills in corpus-based research on talk-in-interaction” (CHORD-talk-in-interaction ). Piattaforme per corpora orali multimediali devono tuttavia ancora essere sviluppate in Svizzera.</p>

<p>Tornando a ShareTIGR, il progetto durerà un anno e sarà coinvolto il team di InfinIta (Johanna Mieczikowski, Elena Battaglia e Christian Geddo ), che è stato presente sul campo e ha rivisto le trascrizioni, rafforzato nei primi mesi dal contributo di una collaboratrice attiva anche in CHORD-talk-in-interaction ( Nina Profazi ). Durante quest’anno, in parallelo al lavoro sui dati completeremo man mano la descrizione del corpus TIGR sul sito del progetto e condivideremo la nostra esperienza tramite il blog, a più voci e in due lingue (italiano e inglese). Ci rivolgiamo a studiose e studiosi di linguistica e delle scienze sociali, a persone interessate alle digital humanities, a specialisti della gestione di dati, a divulgatori scientifici e al pubblico interessato. Usando diversi canali, dai convegni scientifici alle pagine web, il blog e i social media, intendiamo trattare la preparazione del corpus TIGR come un caso studio che permetta di riflettere su sfide e opportunità, problemi e soluzioni che riguardano più generalmente gli open research data (ORD ) in linguistica e in campi affini.</p>

<p>FORSE SI POTREBBERO RACCOGLIERE TUTTI I LINK IN FONDO</p>
  </section>


    </main>
    


<footer class="background" style="--image: url('/seminari/images/background.jpg')" data-dark="true" data-size="wide">
  <!--
    <div>
      Extra details like contact info or address
    </div>
  -->

  <div>
    
      
      
      



  <div class="button-wrapper">
    <a class="button" href="mailto:lilec.lab@unibo.it" data-tooltip="Email" data-style="bare" aria-label="Email">
      <i class="icon fa-solid fa-envelope"></i>
      
    </a>
  </div>


    
      
      
      



  <div class="button-wrapper">
    <a class="button" href="https://orcid.org/0000-0001-8713-9213" data-tooltip="ORCID" data-style="bare" aria-label="ORCID">
      <i class="icon fa-brands fa-orcid"></i>
      
    </a>
  </div>


    
      
      
      



  <div class="button-wrapper">
    <a class="button" href="https://scholar.google.com/citations?user=ETJoidYAAAAJ" data-tooltip="Google Scholar" data-style="bare" aria-label="Google Scholar">
      <i class="icon fa-brands fa-google"></i>
      
    </a>
  </div>


    
      
      
      



  <div class="button-wrapper">
    <a class="button" href="https://github.com/LaboratorioSperimentale" data-tooltip="GitHub" data-style="bare" aria-label="GitHub">
      <i class="icon fa-brands fa-github"></i>
      
    </a>
  </div>


    
      
      
      



  <div class="button-wrapper">
    <a class="button" href="https://twitter.com/LaboratorioSperimentale" data-tooltip="Twitter" data-style="bare" aria-label="Twitter">
      <i class="icon fa-brands fa-twitter"></i>
      
    </a>
  </div>


    
      
      
      



  <div class="button-wrapper">
    <a class="button" href="https://youtube.com/LaboratorioSperimentale" data-tooltip="YouTube" data-style="bare" aria-label="YouTube">
      <i class="icon fa-brands fa-youtube"></i>
      
    </a>
  </div>


    
  </div>

  <div>
    © 2025
    LABORATORIO SPERIMENTALE
      |   Built with
    <a href="https://github.com/greenelab/lab-website-template">
      Lab Website Template
    </a>
  </div>

  <input type="checkbox" class="dark-toggle" data-tooltip="Dark mode" aria-label="toggle dark mode" oninput="onDarkToggleChange(event)">
</footer>

  </body>
</html>
